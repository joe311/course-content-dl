
<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<title>Tutorial 2: Deep MLPs â€” Neuromatch Academy: Deep Learning</title>
<link href="../../../_static/css/theme.css" rel="stylesheet"/>
<link href="../../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet"/>
<link href="../../../_static/vendor/fontawesome/5.13.0/css/all.min.css" rel="stylesheet"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2" rel="preload" type="font/woff2"/>
<link as="font" crossorigin="" href="../../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2" rel="preload" type="font/woff2"/>
<link href="../../../_static/pygments.css" rel="stylesheet" type="text/css">
<link href="../../../_static/sphinx-book-theme.e8e5499552300ddf5d7adccae7cc3b70.css" rel="stylesheet" type="text/css">
<link href="../../../_static/togglebutton.css" rel="stylesheet" type="text/css">
<link href="../../../_static/copybutton.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/mystnb.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/sphinx-thebe.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" rel="stylesheet" type="text/css"/>
<link href="../../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" rel="stylesheet" type="text/css"/>
<link as="script" href="../../../_static/js/index.1c5a1a01449ed65a7b51.js" rel="preload"/>
<script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
<script src="../../../_static/jquery.js"></script>
<script src="../../../_static/underscore.js"></script>
<script src="../../../_static/doctools.js"></script>
<script src="../../../_static/togglebutton.js"></script>
<script src="../../../_static/clipboard.min.js"></script>
<script src="../../../_static/copybutton.js"></script>
<script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
<script src="../../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
<script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
<script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
<script async="async" src="../../../_static/sphinx-thebe.js"></script>
<script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
<link href="../../../_static/nma-logo-square-4xp.jpg" rel="shortcut icon">
<link href="../../../genindex.html" rel="index" title="Index"/>
<link href="../../../search.html" rel="search" title="Search"/>
<link href="../../W1D4_Optimization/chapter_title.html" rel="next" title="Optimization"/>
<link href="W1D3_Tutorial1.html" rel="prev" title="Tutorial 1: Biological vs. Artificial neurons"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<meta content="en" name="docsearch:language"/>
</link></link></link></link></head>
<body data-offset="80" data-spy="scroll" data-target="#bd-toc-nav">
<div class="container-fluid" id="banner"></div>
<div class="container-xl">
<div class="row">
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
<div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
<img alt="logo" class="logo" src="../../../_static/nma-logo-square-4xp.jpg"/>
<h1 class="site-logo" id="site-title">Neuromatch Academy: Deep Learning</h1>
</a>
</div><form action="../../../search.html" class="bd-search d-flex align-items-center" method="get">
<i class="icon fas fa-search"></i>
<input aria-label="Search this book..." autocomplete="off" class="form-control" id="search-input" name="q" placeholder="Search this book..." type="search"/>
</form><nav aria-label="Main navigation" class="bd-links" id="bd-docs-nav">
<div class="bd-toc-item active">
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../intro.html">
   Introduction
  </a>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../Schedule/schedule_intro.html">
   Schedule
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox">
<label for="toctree-checkbox-1">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/daily_schedules.html">
     General schedule
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/shared_calendars.html">
     Shared calendars
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../Schedule/timezone_widget.html">
     Timezone widget
    </a>
</li>
</ul>
</input></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../TechnicalHelp/tech_intro.html">
   Technical Help
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
<label for="toctree-checkbox-2">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2 has-children">
<a class="reference internal" href="../../TechnicalHelp/Jupyterbook.html">
     Using jupyterbook
    </a>
<input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
<label for="toctree-checkbox-3">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_colab.html">
       Using Google Colab
      </a>
</li>
<li class="toctree-l3">
<a class="reference internal" href="../../TechnicalHelp/Tutorial_kaggle.html">
       Using Kaggle
      </a>
</li>
</ul>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../TechnicalHelp/Discord.html">
     Using Discord
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  The Basics
 </span>
</p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/chapter_title.html">
   Basics And Pytorch (W1D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
<label for="toctree-checkbox-4">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D1_BasicsAndPytorch/student/W1D1_Tutorial1.html">
     Tutorial 1: PyTorch
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/chapter_title.html">
   Linear Deep Learning (W1D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
<label for="toctree-checkbox-5">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial1.html">
     Tutorial 1: Gradient Descent and AutoGrad
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial2.html">
     Tutorial 2: Learning Hyperparameters
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D2_LinearDeepLearning/student/W1D2_Tutorial3.html">
     Tutorial 3: Deep linear neural networks
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 current active has-children">
<a class="reference internal" href="../chapter_title.html">
   Multi Layer Perceptrons (W1D3)
  </a>
<input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
<label for="toctree-checkbox-6">
<i class="fas fa-chevron-down">
</i>
</label>
<ul class="current">
<li class="toctree-l2">
<a class="reference internal" href="W1D3_Tutorial1.html">
     Tutorial 1: Biological vs. Artificial neurons
    </a>
</li>
<li class="toctree-l2 current active">
<a class="current reference internal" href="#">
     Tutorial 2: Deep MLPs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D4_Optimization/chapter_title.html">
   Optimization (W1D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
<label for="toctree-checkbox-7">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D4_Optimization/student/W1D4_Tutorial1.html">
     Tutorial 1: Optimization techniques
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W1D5_Regularization/chapter_title.html">
   Regularization (W1D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
<label for="toctree-checkbox-8">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial1.html">
     Tutorial 1: Regularization techniques part 1
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W1D5_Regularization/student/W1D5_Tutorial2.html">
     Tutorial 2: Regularization techniques part 2
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Doing more with fewer parameters
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/chapter_title.html">
   Convnets And Recurrent Neural Networks (W2D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
<label for="toctree-checkbox-9">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial1.html">
     Tutorial 1: Introduction to CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial2.html">
     Tutorial 2: Training loop of CNNs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D1_ConvnetsAndRecurrentNeuralNetworks/student/W2D1_Tutorial3.html">
     Tutorial 3: Introduction to RNNs
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D2_ModernConvnets/chapter_title.html">
   Modern Convnets (W2D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
<label for="toctree-checkbox-10">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial1.html">
     Tutorial 1: Learn how to use modern convnets
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D2_ModernConvnets/student/W2D2_Tutorial2.html">
     Tutorial 2: Facial recognition using modern convnets
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/chapter_title.html">
   Modern Recurrent Neural Networks (W2D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
<label for="toctree-checkbox-11">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial1.html">
     Tutorial 1: Modeling sequencies and encoding text
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D3_ModernRecurrentNeuralNetworks/student/W2D3_Tutorial2.html">
     Tutorial 2: Modern RNNs and their variants
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/chapter_title.html">
   Attention And Transformers (W2D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
<label for="toctree-checkbox-12">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D4_AttentionAndTransformers/student/W2D4_Tutorial1.html">
     Tutorial 1: Learn how to work with Transformers
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W2D5_GenerativeModels/chapter_title.html">
   Generative Models (W2D5)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
<label for="toctree-checkbox-13">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial1.html">
     Tutorial 1: Variational Autoencoders (VAEs)
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial2.html">
     Tutorial 2: Introduction to GANs and Density Ratio Estimation Perspective of GANs
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W2D5_GenerativeModels/student/W2D5_Tutorial3.html">
     Tutorial 3: Conditional GANs and Implications of GAN Technology
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Advanced topics
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/chapter_title.html">
   Unsupervised And Self Supervised Learning (W3D1)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
<label for="toctree-checkbox-14">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D1_UnsupervisedAndSelfSupervisedLearning/student/W3D1_Tutorial1.html">
     Tutorial 1: Un/Self-supervised learning methods
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/chapter_title.html">
   Basic Reinforcement Learning (W3D2)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
<label for="toctree-checkbox-15">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D2_BasicReinforcementLearning/student/W3D2_Tutorial1.html">
     Tutorial 1: Introduction to Reinforcement Learning
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/chapter_title.html">
   Reinforcement Learning For Games (W3D3)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
<label for="toctree-checkbox-16">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D3_ReinforcementLearningForGames/student/W3D3_Tutorial1.html">
     Tutorial 1: Learn to play games with RL
    </a>
</li>
</ul>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../W3D4_ContinualLearning/chapter_title.html">
   Continual Learning (W3D4)
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
<label for="toctree-checkbox-17">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial1.html">
     Tutorial 1: Introduction to Continual Learning
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../W3D4_ContinualLearning/student/W3D4_Tutorial2.html">
     Tutorial 2: Out-of-distribution (OOD) Learning
    </a>
</li>
</ul>
</li>
</ul>
<p class="caption">
<span class="caption-text">
  Project Booklet
 </span>
</p>
<ul class="nav bd-sidenav">
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/README.html">
   Introduction to projects
  </a>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_guidance.html">
   Daily guide for projects
  </a>
</li>
<li class="toctree-l1 has-children">
<a class="reference internal" href="../../../projects/modelingsteps/intro.html">
   Modeling Step-by-Step Guide
  </a>
<input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
<label for="toctree-checkbox-18">
<i class="fas fa-chevron-down">
</i>
</label>
<ul>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_1through2_DL.html">
     Modeling Steps 1 - 2
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_3through4_DL.html">
     Modeling Steps 3 - 4
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_5through6_DL.html">
     Modeling Steps 5 - 6
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_7through9_DL.html">
     Modeling Steps 7 - 9
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/ModelingSteps_10_DL.html">
     Modeling Steps 10
    </a>
</li>
<li class="toctree-l2">
<a class="reference internal" href="../../../projects/modelingsteps/TrainIllusionDataProjectDL.html">
     Example Data Project: the Train Illusion
    </a>
</li>
</ul>
</li>
<li class="toctree-l1">
<a class="reference internal" href="../../../projects/docs/project_templates.html">
   Project Templates
  </a>
</li>
</ul>
</div>
</nav> <!-- To handle the deprecated key -->
<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>
</div>
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
<div class="topbar container-xl fixed-top">
<div class="topbar-contents row">
<div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
<div class="col pl-md-4 topbar-main">
<button aria-controls="site-navigation" aria-expanded="true" aria-label="Toggle navigation" class="navbar-toggler ml-0" data-placement="left" data-target=".site-navigation" data-toggle="tooltip" id="navbar-toggler" title="Toggle navigation" type="button">
<i class="fas fa-bars"></i>
<i class="fas fa-arrow-left"></i>
<i class="fas fa-arrow-up"></i>
</button>
<div class="dropdown-buttons-trigger">
<button aria-label="Download this page" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fas fa-download"></i></button>
<div class="dropdown-buttons">
<!-- ipynb file if we had a myst markdown file -->
<!-- Download raw file -->
<a class="dropdown-buttons" href="../../../_sources/tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.ipynb"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Download source file" type="button">.ipynb</button></a>
<!-- Download PDF via print -->
<button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" id="download-print" onclick="window.print()" title="Print to PDF" type="button">.pdf</button>
</div>
</div>
<!-- Source interaction buttons -->
<div class="dropdown-buttons-trigger">
<button aria-label="Connect with source repository" class="btn btn-secondary topbarbtn" id="dropdown-buttons-trigger"><i class="fab fa-github"></i></button>
<div class="dropdown-buttons sourcebuttons">
<a class="repository-button" href="https://github.com/NeuromatchAcademy/course-content-dl"><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Source repository" type="button"><i class="fab fa-github"></i>repository</button></a>
<a class="issues-button" href="https://github.com/NeuromatchAcademy/course-content-dl/issues/new?title=Issue%20on%20page%20%2Ftutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.html&amp;body=Your%20issue%20content%20here."><button class="btn btn-secondary topbarbtn" data-placement="left" data-toggle="tooltip" title="Open an issue" type="button"><i class="fas fa-lightbulb"></i>open issue</button></a>
</div>
</div>
<!-- Full screen (wrap in <a> to have style consistency -->
<a class="full-screen-button"><button aria-label="Fullscreen mode" class="btn btn-secondary topbarbtn" data-placement="bottom" data-toggle="tooltip" onclick="toggleFullScreen()" title="Fullscreen mode" type="button"><i class="fas fa-expand"></i></button></a>
<!-- Launch buttons -->
</div>
<!-- Table of contents -->
<div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
<i class="fas fa-list"></i> Contents
            </div>
<nav id="bd-toc-nav">
<ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#">
   Tutorial 2: Deep MLPs
  </a>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-objectives">
   Tutorial Objectives
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-slides">
     Tutorial slides
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#setup">
   Setup
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#figure-settings">
     Figure Settings
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#plotting-functions">
     Plotting functions
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#dataset-download">
     Dataset download
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-random-seed">
     Set random seed
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#set-device-gpu-or-cpu-execute-set-device">
     Set device (GPU or CPU). Execute
     <code class="docutils literal notranslate">
<span class="pre">
       set_device()
      </span>
</code>
</a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#tutorial-1-codes">
     Tutorial 1 Codes
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-wider-vs-deeper-networks">
   Section 1: Wider vs deeper networks
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-1-deep-expressivity">
     Video 1: Deep Expressivity
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-1-wide-vs-deep-while-keeping-number-of-parameters-same">
     Coding Exercise 1: Wide vs. Deep while keeping number of parameters same
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-why-the-tradeoff">
     Think! 1: Why the tradeoff?
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-1-1-where-wide-fails">
     Section 1.1: Where Wide Fails
    </a>
<ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-1-1-does-it-generalize-well">
       Think! 1.1: Does it generalize well?
      </a>
</li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-2-deeper-mlps">
   Section 2: Deeper MLPs
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-2-case-study">
     Video 2: Case study
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#coding-exercise-2-dataloader-on-a-real-world-dataset">
     Coding Exercise 2: Dataloader on a real-world dataset
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#think-2-why-first-layer-features-are-high-level">
     Think! 2: why first layer features are high level?
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-the-need-for-good-initialization">
   Section 3: The need for good initialization
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-3-need-for-good-initialization">
     Video 3: Need for Good Initialization
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-1-xavier-initialization">
     Section 3.1: Xavier initialization
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-3-2-initialization-with-transfer-function">
     Section 3.2: Initialization with transfer function
    </a>
</li>
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#best-gain-for-xavier-initialization-with-leaky-relu">
     Best gain for Xavier Initialization with Leaky ReLU
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#section-4-ethical-aspects">
   Section 4: Ethical aspects
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-4-ethics-hype-in-ai">
     Video 4: Ethics: Hype in AI
    </a>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry">
<a class="reference internal nav-link" href="#summary">
   Summary
  </a>
<ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry">
<a class="reference internal nav-link" href="#video-5-outro">
     Video 5: Outro
    </a>
</li>
</ul>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="row" id="main-content">
<div class="col-12 col-md-9 pl-md-3 pr-md-0">
<div>
<p><a href="https://colab.research.google.com/github/NeuromatchAcademy/course-content-dl/blob/main/tutorials/W1D3_MultiLayerPerceptrons/student/W1D3_Tutorial2.ipynb" target="_blank"><img alt="Open In Colab" src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<div class="section" id="tutorial-2-deep-mlps">
<h1>Tutorial 2: Deep MLPs<a class="headerlink" href="#tutorial-2-deep-mlps" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Week 1, Day 3: Multi Layer Perceptrons</strong></p>
<p><strong>By Neuromatch Academy</strong></p>
<p><strong>Content creators:</strong> Arash Ash, Surya Ganguli</p>
<p><strong>Content reviewers:</strong> Saeed Salehi, Felix Bartsch, Yu-Fang Yang, Melvin Selim Atay</p>
<p><strong>Content editors:</strong> B Gagana, Spiros Chavlis</p>
<p><strong>Production editors:</strong> Anoop Kulkarni, Spiros Chavlis</p>
<p><strong>Our 2021 Sponsors, including Presenting Sponsor Facebook Reality Labs</strong></p>
<p align="center"><img src="https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True"/></p></div>
<hr class="docutils"/>
<div class="section" id="tutorial-objectives">
<h1>Tutorial Objectives<a class="headerlink" href="#tutorial-objectives" title="Permalink to this headline">Â¶</a></h1>
<p>In this tutorial, we will dive deeper into MLPs and see more of their mathematical and practical aspects. Today we are going to see why MLPs:</p>
<ul class="simple">
<li><p>can be deep or wide</p></li>
<li><p>dependant on transfer functions</p></li>
<li><p>sensitive to initialization</p></li>
</ul>
<div class="section" id="tutorial-slides">
<h2>Tutorial slides<a class="headerlink" href="#tutorial-slides" title="Permalink to this headline">Â¶</a></h2>
<p>These are the slides for the videos in all tutorials today</p>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<div class="output text_html">
<iframe allowfullscreen="" frameborder="0" height="480" src="https://mfr.ca-1.osf.io/render?url=https://osf.io/ed65b/?direct%26mode=render%26action=download%26mode=render" width="854"></iframe>
</div></div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="setup">
<h1>Setup<a class="headerlink" href="#setup" title="Permalink to this headline">Â¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Imports</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">pathlib</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">torchvision.datasets</span> <span class="kn">import</span> <span class="n">ImageFolder</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">TensorDataset</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="n">make_grid</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">display</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="figure-settings">
<h2>Figure Settings<a class="headerlink" href="#figure-settings" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Figure Settings</span>
<span class="kn">import</span> <span class="nn">ipywidgets</span> <span class="k">as</span> <span class="nn">widgets</span>       <span class="c1"># interactive display</span>
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = 'retina'
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">"https://raw.githubusercontent.com/NeuromatchAcademy/content-creation/main/nma.mplstyle"</span><span class="p">)</span>
<span class="n">my_layout</span> <span class="o">=</span> <span class="n">widgets</span><span class="o">.</span><span class="n">Layout</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="plotting-functions">
<h2>Plotting functions<a class="headerlink" href="#plotting-functions" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Plotting functions</span>
<span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
  <span class="n">img</span> <span class="o">=</span> <span class="n">img</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">+</span> <span class="mf">0.5</span>     <span class="c1"># unnormalize</span>
  <span class="n">npimg</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">npimg</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">progress</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">HTML</span><span class="p">(</span><span class="s2">"""</span>
<span class="s2">      &lt;label for="file"&gt;Training loss: </span><span class="si">{loss}</span><span class="s2">&lt;/label&gt;</span>
<span class="s2">      &lt;progress</span>
<span class="s2">          value='</span><span class="si">{epoch}</span><span class="s2">'</span>
<span class="s2">          max='</span><span class="si">{epochs}</span><span class="s2">',</span>
<span class="s2">          style='width: 100%'</span>
<span class="s2">      &gt;</span>
<span class="s2">          </span><span class="si">{epoch}</span><span class="s2"></span>
<span class="s2">      &lt;/progress&gt;</span>
<span class="s2">  """</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="n">loss</span><span class="p">,</span> <span class="n">epoch</span><span class="o">=</span><span class="n">epoch</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="dataset-download">
<h2>Dataset download<a class="headerlink" href="#dataset-download" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Dataset download</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
<span class="o">!</span>rm -r AnimalFaces32x32/
<span class="o">!</span>git clone https://github.com/arashash/AnimalFaces32x32
<span class="o">!</span>rm -r afhq/
<span class="o">!</span>unzip ./AnimalFaces32x32/afhq_32x32.zip
<span class="n">clear_output</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-random-seed">
<h2>Set random seed<a class="headerlink" href="#set-random-seed" title="Permalink to this headline">Â¶</a></h2>
<p>Executing <code class="docutils literal notranslate"><span class="pre">set_seed(seed=seed)</span></code> you are setting the seed</p>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set random seed</span>

<span class="c1"># @markdown Executing `set_seed(seed=seed)` you are setting the seed</span>

<span class="c1"># for DL its critical to set the random seed so that students can have a</span>
<span class="c1"># baseline to compare their results to expected results.</span>
<span class="c1"># Read more here: https://pytorch.org/docs/stable/notes/randomness.html</span>

<span class="c1"># Call `set_seed` function in the exercises to ensure reproducibility.</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">torch</span>

<span class="k">def</span> <span class="nf">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="mi">2</span> <span class="o">**</span> <span class="mi">32</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>

  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">'Random seed </span><span class="si">{</span><span class="n">seed</span><span class="si">}</span><span class="s1"> has been set.'</span><span class="p">)</span>


<span class="c1"># In case that `DataLoader` is used</span>
<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">worker_id</span><span class="p">):</span>
  <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
  <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
  <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="set-device-gpu-or-cpu-execute-set-device">
<h2>Set device (GPU or CPU). Execute <code class="docutils literal notranslate"><span class="pre">set_device()</span></code><a class="headerlink" href="#set-device-gpu-or-cpu-execute-set-device" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Set device (GPU or CPU). Execute `set_device()`</span>
<span class="c1"># especially if torch modules used.</span>

<span class="c1"># inform the user if the notebook uses GPU or CPU.</span>

<span class="k">def</span> <span class="nf">set_device</span><span class="p">():</span>
  <span class="n">device</span> <span class="o">=</span> <span class="s2">"cuda"</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">"cpu"</span>
  <span class="k">if</span> <span class="n">device</span> <span class="o">!=</span> <span class="s2">"cuda"</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"WARNING: For this notebook to perform best, "</span>
          <span class="s2">"if possible, in the menu under `Runtime` -&gt; "</span>
          <span class="s2">"`Change runtime type.`  select `GPU` "</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"GPU is enabled in this notebook."</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">device</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">DEVICE</span> <span class="o">=</span> <span class="n">set_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
WARNING: For this notebook to perform best, if possible, in the menu under `Runtime` -&gt; `Change runtime type.`  select `GPU` 
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="tutorial-1-codes">
<h2>Tutorial 1 Codes<a class="headerlink" href="#tutorial-1-codes" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># @title Tutorial 1 Codes</span>
<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">actv</span><span class="p">,</span> <span class="n">input_feature_num</span><span class="p">,</span> <span class="n">hidden_unit_nums</span><span class="p">,</span> <span class="n">output_feature_num</span><span class="p">):</span>
    <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">input_feature_num</span> <span class="o">=</span> <span class="n">input_feature_num</span> <span class="c1"># save the input size for reshapinng later</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span> <span class="c1"># Initialize layers of MLP</span>

    <span class="n">in_num</span> <span class="o">=</span> <span class="n">input_feature_num</span> <span class="c1"># initialize the temporary input feature to each layer</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">hidden_unit_nums</span><span class="p">)):</span> <span class="c1"># Loop over layers and create each one</span>
      <span class="n">out_num</span> <span class="o">=</span> <span class="n">hidden_unit_nums</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="c1"># assign the current layer hidden unit from list</span>
      <span class="n">layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_num</span><span class="p">,</span> <span class="n">out_num</span><span class="p">)</span> <span class="c1"># use nn.Linear to define the layer</span>
      <span class="n">in_num</span> <span class="o">=</span> <span class="n">out_num</span> <span class="c1"># assign next layer input using current layer output</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">'Linear_</span><span class="si">%d</span><span class="s1">'</span><span class="o">%</span><span class="k">i</span>, layer) # append layer to the model with a name

      <span class="n">actv_layer</span> <span class="o">=</span> <span class="nb">eval</span><span class="p">(</span><span class="s1">'nn.</span><span class="si">%s</span><span class="s1">'</span><span class="o">%</span><span class="k">actv</span>) # Assign activation function (eval allows us to instantiate object from string)
      <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">'Activation_</span><span class="si">%d</span><span class="s1">'</span><span class="o">%</span><span class="k">i</span>, actv_layer) # append activation to the model with a name

    <span class="n">out_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_num</span><span class="p">,</span> <span class="n">output_feature_num</span><span class="p">)</span> <span class="c1"># Create final layer</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s1">'Output_Linear'</span><span class="p">,</span> <span class="n">out_layer</span><span class="p">)</span> <span class="c1"># append the final layer</span>

  <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># reshape inputs to (batch_size, input_feature_num)</span>
    <span class="c1"># just in case the input vector is not 2D, like an image!</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_feature_num</span><span class="p">)</span>

    <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># forward pass of MLP</span>
    <span class="k">return</span> <span class="n">logits</span>

<span class="n">SEED</span> <span class="o">=</span> <span class="mi">2021</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mf">0.4</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">t</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="o">*</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">K</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">):</span>
  <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">:(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span><span class="o">*</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="n">K</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">t</span><span class="o">+</span><span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>   <span class="c1"># [TO-DO]</span>
  <span class="n">X</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">:(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">t</span><span class="o">*</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="o">/</span><span class="n">K</span><span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">t</span><span class="o">+</span><span class="n">k</span><span class="p">))</span> <span class="o">+</span> <span class="n">sigma</span><span class="o">**</span><span class="mi">2</span><span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">))</span>   <span class="c1"># [TO-DO]</span>
  <span class="n">y</span><span class="p">[</span><span class="n">k</span><span class="o">*</span><span class="n">N</span><span class="p">:(</span><span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="n">N</span><span class="p">]</span> <span class="o">=</span> <span class="n">k</span>

<span class="c1"># Shuffling</span>
<span class="n">shuffled_indeces</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randperm</span><span class="p">(</span><span class="n">K</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">shuffled_indeces</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">shuffled_indeces</span><span class="p">]</span>

<span class="c1"># Test Train splitting</span>
<span class="n">test_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.2</span><span class="o">*</span><span class="n">N</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[:</span><span class="n">test_size</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">test_size</span><span class="p">:]</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>
<span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
<span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">test_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                         <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                         <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                         <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">,</span>
                         <span class="p">)</span>

<span class="n">train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span>
                          <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                          <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                          <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                          <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">,</span>
                          <span class="p">)</span>


<span class="k">def</span> <span class="nf">train_test_classification</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                              <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span>
                              <span class="n">device</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                              <span class="n">training_plot</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="n">progress_bar</span> <span class="o">=</span> <span class="n">display</span><span class="p">(</span><span class="n">progress</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">),</span> <span class="n">display_id</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

  <span class="n">net</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">training_losses</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>
    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">train_loader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
      <span class="c1"># get the inputs; data is a list of [inputs, labels]</span>
      <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
      <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

      <span class="c1"># zero the parameter gradients</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

      <span class="c1"># forward + backward + optimize</span>
      <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

      <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
      <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
      <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

      <span class="c1"># print statistics</span>
      <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
        <span class="n">training_losses</span> <span class="o">+=</span> <span class="p">[</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">9</span><span class="p">:</span>    <span class="c1"># update every 10 mini-batches</span>
          <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">progress</span><span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">))</span>
          <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

  <span class="n">net</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
  <span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">data_loader</span><span class="p">):</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">data_loader</span><span class="p">:</span>
      <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>
      <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
      <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

      <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
      <span class="n">_</span><span class="p">,</span> <span class="n">predicted</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
      <span class="n">total</span> <span class="o">+=</span> <span class="n">labels</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
      <span class="n">correct</span> <span class="o">+=</span> <span class="p">(</span><span class="n">predicted</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

    <span class="n">acc</span> <span class="o">=</span> <span class="mi">100</span> <span class="o">*</span> <span class="n">correct</span> <span class="o">/</span> <span class="n">total</span>
    <span class="k">return</span> <span class="n">total</span><span class="p">,</span> <span class="n">acc</span>

  <span class="n">train_total</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">train_loader</span><span class="p">)</span>
  <span class="n">test_total</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">test</span><span class="p">(</span><span class="n">test_loader</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">verbose</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Accuracy on the </span><span class="si">%d</span><span class="s1"> training samples: </span><span class="si">%0.2f</span><span class="s1"> </span><span class="si">%%</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_total</span><span class="p">,</span> <span class="n">train_acc</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Accuracy on the </span><span class="si">%d</span><span class="s1"> testing samples: </span><span class="si">%0.2f</span><span class="s1"> </span><span class="si">%%</span><span class="s1">'</span> <span class="o">%</span> <span class="p">(</span><span class="n">test_total</span><span class="p">,</span> <span class="n">test_acc</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">training_plot</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">training_losses</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'Batch'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'Training loss'</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_acc</span>


<span class="k">def</span> <span class="nf">sample_grid</span><span class="p">(</span><span class="n">M</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">):</span>
  <span class="n">ii</span><span class="p">,</span> <span class="n">jj</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">x_max</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span><span class="n">M</span><span class="p">),</span>
                          <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">x_max</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">M</span><span class="p">))</span>
  <span class="n">X_all</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ii</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
                     <span class="n">jj</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)],</span>
                     <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">X_all</span>


<span class="k">def</span> <span class="nf">plot_decision_map</span><span class="p">(</span><span class="n">X_all</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span> <span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">):</span>
  <span class="n">decision_map</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

  <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)):</span>
    <span class="n">indeces</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_all</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">X_all</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;</span> <span class="n">eps</span>    <span class="c1"># [TO-DO]</span>
    <span class="n">decision_map</span><span class="p">[</span><span class="n">indeces</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">K</span> <span class="o">+</span> <span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>

  <span class="n">decision_map</span> <span class="o">=</span> <span class="n">decision_map</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">decision_map</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="n">x_max</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="o">-</span><span class="n">x_max</span><span class="p">,</span> <span class="n">x_max</span><span class="p">],</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">'jet'</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-1-wider-vs-deeper-networks">
<h1>Section 1: Wider vs deeper networks<a class="headerlink" href="#section-1-wider-vs-deeper-networks" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="video-1-deep-expressivity">
<h2>Video 1: Deep Expressivity<a class="headerlink" href="#video-1-deep-expressivity" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "b5219f42d36542649a2838b3cf643418"}
</script></div>
</div>
</div>
<div class="section" id="coding-exercise-1-wide-vs-deep-while-keeping-number-of-parameters-same">
<h2>Coding Exercise 1: Wide vs. Deep while keeping number of parameters same<a class="headerlink" href="#coding-exercise-1-wide-vs-deep-while-keeping-number-of-parameters-same" title="Permalink to this headline">Â¶</a></h2>
<p>Letâ€™s find the optimal number of hidden layers under a fixed number of parameters constraint!</p>
<p>But first, we need a model parameter counter. You could iterate over the model layers by calling <code class="docutils literal notranslate"><span class="pre">.parameters()</span></code> and then use <code class="docutils literal notranslate"><span class="pre">.numel()</span></code> to count the layer parameters. Also, you can use <a class="reference external" href="https://pytorch.org/docs/stable/notes/autograd.html"><code class="docutils literal notranslate"><span class="pre">requires_grad</span></code></a> attribute to make sure itâ€™s a trainable parameter. E.g.,</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
<p>After defining the counter function, we will step by step increase the depth and then iterate over the possible number of hidden units (assuming same for all hidden layers); then using our parameter counter choose the number of hidden units that results in overall close to <code class="docutils literal notranslate"><span class="pre">max_par_count</span></code> parameters.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_depth_optimizer</span><span class="p">(</span><span class="n">max_par_count</span><span class="p">,</span>  <span class="n">max_hidden_layer</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in all missing code below (...),</span>
  <span class="c1"># then remove or comment the line below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define the depth optimizer function"</span><span class="p">)</span>
  <span class="c1">###################################################################</span>

  <span class="k">def</span> <span class="nf">count_parameters</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">par_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
      <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
        <span class="n">par_count</span> <span class="o">+=</span> <span class="o">...</span>
    <span class="k">return</span> <span class="n">par_count</span>

  <span class="c1"># number of hidden layers to try</span>
  <span class="n">hidden_layers</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># test test score list</span>
  <span class="n">test_scores</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="k">for</span> <span class="n">hidden_layer</span> <span class="ow">in</span> <span class="n">hidden_layers</span><span class="p">:</span>
    <span class="c1"># Initialize the hidden units in each hidden layer to be 1</span>
    <span class="n">hidden_units</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int</span><span class="p">)</span>

    <span class="c1"># Define the the with hidden units equal to 1</span>
    <span class="n">wide_net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="s1">'ReLU()'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">par_count</span> <span class="o">=</span> <span class="n">count_parameters</span><span class="p">(</span><span class="n">wide_net</span><span class="p">)</span>

    <span class="c1"># increment hidden_units and repeat until the par_count reaches the desired count</span>
    <span class="k">while</span> <span class="n">par_count</span> <span class="o">&lt;</span> <span class="n">max_par_count</span><span class="p">:</span>
      <span class="n">hidden_units</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="n">wide_net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="s1">'ReLU()'</span><span class="p">,</span> <span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">hidden_units</span><span class="p">,</span> <span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
      <span class="n">par_count</span> <span class="o">=</span> <span class="o">...</span>

    <span class="c1"># Train it</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">wide_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">train_test_classification</span><span class="p">(</span><span class="n">wide_net</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                                            <span class="n">train_loader</span><span class="p">,</span> <span class="n">test_loader</span><span class="p">,</span>
                                            <span class="n">DEVICE</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="n">test_scores</span> <span class="o">+=</span> <span class="p">[</span><span class="n">test_acc</span><span class="p">]</span>

  <span class="k">return</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">test_scores</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">max_par_count</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">max_hidden_layer</span> <span class="o">=</span> <span class="mi">5</span>
<span class="c1">## Uncomment below to test your function</span>
<span class="c1"># hidden_layers, test_scores = run_depth_optimizer(max_par_count, max_hidden_layer, DEVICE)</span>
<span class="c1"># plt.xlabel('# of hidden layers')</span>
<span class="c1"># plt.ylabel('Test accuracy')</span>
<span class="c1"># plt.plot(hidden_layers, test_scores)</span>
<span class="c1"># plt.show()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_67b86937.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D3_MultiLayerPerceptrons/static/W1D3_Tutorial2_Solution_67b86937_11.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D3_MultiLayerPerceptrons/static/W1D3_Tutorial2_Solution_67b86937_11.png" style="width: 1120.0px; height: 832.0px;"/></a>
</div>
<div class="section" id="think-1-why-the-tradeoff">
<h2>Think! 1: Why the tradeoff?<a class="headerlink" href="#think-1-why-the-tradeoff" title="Permalink to this headline">Â¶</a></h2>
<p>Here we see that there is a particular number of hidden layers that is optimum. Why do you think increasing hidden layers after a certain point hurt in this scenario?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_4c626e50.py"><em>Click for solution</em></a></p>
</div>
<div class="section" id="section-1-1-where-wide-fails">
<h2>Section 1.1: Where Wide Fails<a class="headerlink" href="#section-1-1-where-wide-fails" title="Permalink to this headline">Â¶</a></h2>
<p>Letâ€™s use the same Spiral dataset generated before with two features. And then add more polynomial features (which makes the first layer wider). And finally, train a single Linear layer. We could use the same MLP network with no hidden layers (though it would not be called an MLP anymore!).</p>
<p>Note that we will add polynomial terms upto <span class="math notranslate nohighlight">\(P=50\)</span> which means that for every <span class="math notranslate nohighlight">\(x_1^n x_2^m\)</span> term, <span class="math notranslate nohighlight">\(n+m\leq P\)</span>. Now itâ€™s fun math excercise to prove why the total number of polynomial features upto <span class="math notranslate nohighlight">\(P\)</span> becomes,</p>
<div class="amsmath math notranslate nohighlight" id="equation-b48a8acb-98d1-4187-bdab-85928196557b">
<span class="eqno">(34)<a class="headerlink" href="#equation-b48a8acb-98d1-4187-bdab-85928196557b" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
\text{# of terms} = \frac{(P+1)(P+2)}{2}
\end{equation}\]</div>
<p>Also, we donâ€™t need the polynomial term with degree zero (which is the constatnt term) since <code class="docutils literal notranslate"><span class="pre">nn.Linear</span></code> layers have bias terms. Therefore we will have one fewer polynomial feature.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_poly_clasification</span><span class="p">(</span><span class="n">poly_degree</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>

  <span class="k">def</span> <span class="nf">make_poly_features</span><span class="p">(</span><span class="n">poly_degree</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
    <span class="c1"># Define the number of polynomial features except the bias term</span>
    <span class="n">num_features</span> <span class="o">=</span> <span class="p">(</span><span class="n">poly_degree</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span><span class="o">*</span><span class="p">(</span><span class="n">poly_degree</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
    <span class="n">poly_X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_features</span><span class="p">))</span>
    <span class="n">count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">poly_degree</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">poly_degree</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
         <span class="c1"># no need to add zero degree since model has biases</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">+</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
          <span class="k">if</span> <span class="n">j</span> <span class="o">+</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">poly_degree</span><span class="p">:</span>
            <span class="c1"># Define the polynomial term</span>
            <span class="n">poly_X</span><span class="p">[:,</span> <span class="n">count</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="n">i</span> <span class="o">*</span> <span class="n">X</span> <span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="n">j</span>
            <span class="n">count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">poly_X</span><span class="p">,</span> <span class="n">num_features</span>

  <span class="n">poly_X_test</span><span class="p">,</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">make_poly_features</span><span class="p">(</span><span class="n">poly_degree</span><span class="p">,</span> <span class="n">X_test</span><span class="p">)</span>
  <span class="n">poly_X_train</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_poly_features</span><span class="p">(</span><span class="n">poly_degree</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>

  <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">128</span>

  <span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
  <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="n">poly_test_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">poly_X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
  <span class="n">poly_test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">poly_test_data</span><span class="p">,</span>
                                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                                <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="n">poly_train_data</span> <span class="o">=</span> <span class="n">TensorDataset</span><span class="p">(</span><span class="n">poly_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
  <span class="n">poly_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">poly_train_data</span><span class="p">,</span>
                                 <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                 <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                 <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                 <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                 <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="c1"># define a linear model using MLP class</span>
  <span class="n">poly_net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="s1">'ReLU()'</span><span class="p">,</span> <span class="n">num_features</span><span class="p">,</span> <span class="p">[],</span> <span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

  <span class="c1"># Train it!</span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">poly_net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
  <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_classification</span><span class="p">(</span><span class="n">poly_net</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                                   <span class="n">poly_train_loader</span><span class="p">,</span> <span class="n">poly_test_loader</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span>
                                   <span class="n">num_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
  <span class="c1"># Test it</span>
  <span class="n">X_all</span> <span class="o">=</span> <span class="n">sample_grid</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
  <span class="n">poly_X_all</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">make_poly_features</span><span class="p">(</span><span class="n">poly_degree</span><span class="p">,</span> <span class="n">X_all</span><span class="p">)</span>
  <span class="n">y_pred</span> <span class="o">=</span> <span class="n">poly_net</span><span class="p">(</span><span class="n">poly_X_all</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>

  <span class="c1"># Plot it</span>
  <span class="n">plot_decision_map</span><span class="p">(</span><span class="n">X_all</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">X_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

  <span class="k">return</span> <span class="n">num_features</span>


<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">max_poly_degree</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">num_features</span> <span class="o">=</span> <span class="n">run_poly_clasification</span><span class="p">(</span><span class="n">max_poly_degree</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">SEED</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Number of features: </span><span class="si">%d</span><span class="s1">'</span><span class="o">%</span><span class="k">num_features</span>)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Random seed 2021 has been set.
</pre></div>
</div>
<div class="output text_html">
<label for="file">Training loss: 0.6024731934070587</label>
<progress ,="" max="100" style="width: 100%" value="100">
    100
</progress>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on the 3800 training samples: 73.34 %
Accuracy on the 200 testing samples: 69.50 %
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">KeyboardInterrupt</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">ipykernel_2082</span><span class="o">/</span><span class="mf">1050415152.</span><span class="n">py</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">     </span><span class="mi">62</span> <span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">63</span> <span class="n">max_poly_degree</span> <span class="o">=</span> <span class="mi">50</span>
<span class="ne">---&gt; </span><span class="mi">64</span> <span class="n">num_features</span> <span class="o">=</span> <span class="n">run_poly_clasification</span><span class="p">(</span><span class="n">max_poly_degree</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span> <span class="n">SEED</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">65</span> <span class="nb">print</span><span class="p">(</span><span class="s1">'Number of features: </span><span class="si">%d</span><span class="s1">'</span><span class="o">%</span><span class="k">num_features</span>)

<span class="nn">/tmp/ipykernel_2082/1050415152.py</span> in <span class="ni">run_poly_clasification</span><span class="nt">(poly_degree, device, seed)</span>
<span class="g g-Whitespace">     </span><span class="mi">54</span> 
<span class="g g-Whitespace">     </span><span class="mi">55</span>   <span class="c1"># Plot it</span>
<span class="ne">---&gt; </span><span class="mi">56</span>   <span class="n">plot_decision_map</span><span class="p">(</span><span class="n">X_all</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">X_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">(),</span> <span class="n">y_test</span><span class="o">.</span><span class="n">cpu</span><span class="p">())</span>
<span class="g g-Whitespace">     </span><span class="mi">57</span>   <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="g g-Whitespace">     </span><span class="mi">58</span> 

<span class="nn">/tmp/ipykernel_2082/1638190197.py</span> in <span class="ni">plot_decision_map</span><span class="nt">(X_all, y_pred, X_test, y_test, M, x_max, eps)</span>
<span class="g g-Whitespace">    </span><span class="mi">155</span>   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_test</span><span class="p">)):</span>
<span class="g g-Whitespace">    </span><span class="mi">156</span>     <span class="n">indeces</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_all</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">X_all</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">X_test</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span> <span class="o">&lt;</span> <span class="n">eps</span>    <span class="c1"># [TO-DO]</span>
<span class="ne">--&gt; </span><span class="mi">157</span>     <span class="n">decision_map</span><span class="p">[</span><span class="n">indeces</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">K</span> <span class="o">+</span> <span class="n">y_test</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">158</span> 
<span class="g g-Whitespace">    </span><span class="mi">159</span>   <span class="n">decision_map</span> <span class="o">=</span> <span class="n">decision_map</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">M</span><span class="p">)</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="section" id="think-1-1-does-it-generalize-well">
<h3>Think! 1.1: Does it generalize well?<a class="headerlink" href="#think-1-1-does-it-generalize-well" title="Permalink to this headline">Â¶</a></h3>
<p>Do you think this model is performing well outside its training distribution? Why?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_13c53198.py"><em>Click for solution</em></a></p>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-2-deeper-mlps">
<h1>Section 2: Deeper MLPs<a class="headerlink" href="#section-2-deeper-mlps" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="video-2-case-study">
<h2>Video 2: Case study<a class="headerlink" href="#video-2-case-study" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="coding-exercise-2-dataloader-on-a-real-world-dataset">
<h2>Coding Exercise 2: Dataloader on a real-world dataset<a class="headerlink" href="#coding-exercise-2-dataloader-on-a-real-world-dataset" title="Permalink to this headline">Â¶</a></h2>
<p>Letâ€™s build our first real-world dataset loader with Data Preprocessing and Augmentation! And we will use the Torchvision transforms to do it.</p>
<p>Weâ€™d like to have a simple data augmentation with the following steps:</p>
<ul class="simple">
<li><p>Random rotation with 10 degrees (RandomRotation)</p></li>
<li><p>Random horizontal flipping (RandomHorizontalFlip)</p></li>
</ul>
<p>and weâ€™d like a preprocessing that:</p>
<ul class="simple">
<li><p>makes Pytorch tensors in the range [0, 1] (ToTensor)</p></li>
<li><p>normalizes the input in the range [-1, 1] (Normalize)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data_loaders</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seed</span><span class="p">):</span>
  <span class="c1">####################################################################</span>
  <span class="c1"># Fill in all missing code below (...),</span>
  <span class="c1"># then remove or comment the line below to test your function</span>
  <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">"Define the get data loaders function"</span><span class="p">)</span>
  <span class="c1">###################################################################</span>

  <span class="c1"># define the transform done only during training</span>
  <span class="n">augmentation_transforms</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># define the transform done in training and testing (after augmentation)</span>
  <span class="n">preprocessing_transforms</span> <span class="o">=</span> <span class="o">...</span>

  <span class="c1"># compose them together</span>
  <span class="n">train_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">augmentation_transforms</span> <span class="o">+</span> <span class="n">preprocessing_transforms</span><span class="p">)</span>
  <span class="n">test_transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span><span class="n">preprocessing_transforms</span><span class="p">)</span>

  <span class="c1"># using pathlib to be compatible with all OS's</span>
  <span class="n">data_path</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">(</span><span class="s1">'.'</span><span class="p">)</span><span class="o">/</span><span class="s1">'afhq'</span>

  <span class="c1"># define the dataset objects (they can load one by one)</span>
  <span class="n">img_train_dataset</span> <span class="o">=</span> <span class="n">ImageFolder</span><span class="p">(</span><span class="n">data_path</span><span class="o">/</span><span class="s1">'train'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">train_transform</span><span class="p">)</span>
  <span class="n">img_test_dataset</span> <span class="o">=</span> <span class="n">ImageFolder</span><span class="p">(</span><span class="n">data_path</span><span class="o">/</span><span class="s1">'val'</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">test_transform</span><span class="p">)</span>

  <span class="n">g_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">()</span>
  <span class="n">g_seed</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
  <span class="c1"># define the dataloader objects (they can load batch by batch)</span>
  <span class="n">img_train_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">img_train_dataset</span><span class="p">,</span>
                                <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                                <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>
  <span class="c1"># num_workers can be set to higher if running on Colab Pro TPUs to speed up,</span>
  <span class="c1"># with more than one worker, it will do multithreading to queue batches</span>
  <span class="n">img_test_loader</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">img_test_dataset</span><span class="p">,</span>
                               <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                               <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                               <span class="n">num_workers</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                               <span class="n">worker_init_fn</span><span class="o">=</span><span class="n">seed_worker</span><span class="p">,</span>
                               <span class="n">generator</span><span class="o">=</span><span class="n">g_seed</span><span class="p">)</span>

  <span class="k">return</span> <span class="n">img_train_loader</span><span class="p">,</span> <span class="n">img_test_loader</span>


<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="c1">## Uncomment below to test your function</span>
<span class="c1"># img_train_loader, img_test_loader = get_data_loaders(batch_size, SEED)</span>
<span class="c1">## get some random training images</span>
<span class="c1"># dataiter = iter(img_train_loader)</span>
<span class="c1"># images, labels = dataiter.next()</span>
<span class="c1">## show images</span>
<span class="c1"># imshow(make_grid(images, nrow=8))</span>
</pre></div>
</div>
</div>
</div>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_a50bebe8.py"><em>Click for solution</em></a></p>
<p><em>Example output:</em></p>
<a class="reference internal image-reference" href="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D3_MultiLayerPerceptrons/static/W1D3_Tutorial2_Solution_a50bebe8_1.png"><img align="center" alt="Solution hint" class="align-center" src="https://raw.githubusercontent.com/NeuromatchAcademy/course-content-dl/main/tutorials/W1D3_MultiLayerPerceptrons/static/W1D3_Tutorial2_Solution_a50bebe8_1.png" style="width: 827.0px; height: 827.0px;"/></a>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Train it</span>
<span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="s1">'ReLU()'</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">3e-4</span><span class="p">)</span>
<span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_test_classification</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                                <span class="n">img_train_loader</span><span class="p">,</span> <span class="n">img_test_loader</span><span class="p">,</span> <span class="n">DEVICE</span><span class="p">,</span>
                                <span class="n">num_epochs</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># visualize the feature map</span>
<span class="n">fc1_weights</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">mlp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">fc1_weights</span> <span class="o">/=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">fc1_weights</span><span class="p">))</span>
<span class="n">imshow</span><span class="p">(</span><span class="n">make_grid</span><span class="p">(</span><span class="n">fc1_weights</span><span class="p">,</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="think-2-why-first-layer-features-are-high-level">
<h2>Think! 2: why first layer features are high level?<a class="headerlink" href="#think-2-why-first-layer-features-are-high-level" title="Permalink to this headline">Â¶</a></h2>
<p>Even though itâ€™s three layers deep, we see distinct animal faces in the first layer feature map. Do you think this MLP has a hierarchical feature representation? why?</p>
<p><a class="reference external" href="https://github.com/NeuromatchAcademy/course-content-dl/tree/main//tutorials/W1D3_MultiLayerPerceptrons/solutions/W1D3_Tutorial2_Solution_eb2e554f.py"><em>Click for solution</em></a></p>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-3-the-need-for-good-initialization">
<h1>Section 3: The need for good initialization<a class="headerlink" href="#section-3-the-need-for-good-initialization" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="video-3-need-for-good-initialization">
<h2>Video 3: Need for Good Initialization<a class="headerlink" href="#video-3-need-for-good-initialization" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
<div class="section" id="section-3-1-xavier-initialization">
<h2>Section 3.1: Xavier initialization<a class="headerlink" href="#section-3-1-xavier-initialization" title="Permalink to this headline">Â¶</a></h2>
<p>Let us look at the scale distribution of an output (e.g., a hidden variable)  <span class="math notranslate nohighlight">\(o_i\)</span>  for some fully-connected layer without nonlinearities. With  <span class="math notranslate nohighlight">\(n_{in}\)</span>  inputs  (<span class="math notranslate nohighlight">\(x_j\)</span>)  and their associated weights  <span class="math notranslate nohighlight">\(w_{ij}\)</span>  for this layer. Then an output is given by,</p>
<div class="amsmath math notranslate nohighlight" id="equation-b40f75c5-1ca0-4f32-9120-744bee70c5f3">
<span class="eqno">(35)<a class="headerlink" href="#equation-b40f75c5-1ca0-4f32-9120-744bee70c5f3" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
o_{i} = \sum_{j=1}^{n_\mathrm{in}} w_{ij} x_j
\end{equation}\]</div>
<p>The weights  <span class="math notranslate nohighlight">\(w_{ij}\)</span>  are all drawn independently from the same distribution. Furthermore, let us assume that this distribution has zero mean and variance  <span class="math notranslate nohighlight">\(\sigma^2\)</span> . Note that this does not mean that the distribution has to be Gaussian, just that the mean and variance need to exist. For now, let us assume that the inputs to the layer  <span class="math notranslate nohighlight">\(x_j\)</span> also have zero mean and variance  <span class="math notranslate nohighlight">\(\gamma^2\)</span>  and that they are independent of <span class="math notranslate nohighlight">\(w_{ij}\)</span> and independent of each other. In this case, we can compute the mean and variance of <span class="math notranslate nohighlight">\(o_i\)</span> as follows:</p>
<p>\begin{split}
\begin{aligned}
E[o_i] &amp;= \sum_{j=1}^{n_\mathrm{in}} E[w_{ij} x_j] \ \
&amp;= \sum_{j=1}^{n_\mathrm{in}} E[w_{ij}] E[x_j] = 0, \ \ \
\mathrm{Var}[o_i] &amp;= E[o_i^2] - (E[o_i])^2 \ \
&amp;= \sum_{j=1}^{n_\mathrm{in}} E[w^2_{ij} x^2_j] - 0 \ \
&amp;= \sum_{j=1}^{n_\mathrm{in}} E[w^2_{ij}] E[x^2_j] \ \
&amp;= n_\mathrm{in} \sigma^2 \gamma^2
\end{aligned}
\end{split}</p>
<p>One way to keep the variance fixed is to set <span class="math notranslate nohighlight">\(n_{in}\sigma^2=1\)</span> . Now consider backpropagation. There we face a similar problem, albeit with gradients being propagated from the layers closer to the output. Using the same reasoning as for forward propagation, we see that the gradientsâ€™ variance can blow up unless <span class="math notranslate nohighlight">\(n_{out}\sigma^2=1\)</span> , where  <span class="math notranslate nohighlight">\(n_{out}\)</span> is the number of outputs of this layer. This leaves us in a dilemma: we cannot possibly satisfy both conditions simultaneously. Instead, we simply try to satisfy:</p>
<p>\begin{aligned}
\frac{1}{2} (n_\mathrm{in} + n_\mathrm{out}) \sigma^2 = 1 \text{ or equivalently }
\sigma = \sqrt{\frac{2}{n_\mathrm{in} + n_\mathrm{out}}}
\end{aligned}</p>
<p>This is the reasoning underlying the now-standard and practically beneficial Xavier initialization, named after the first author of its creators [Glorot &amp; Bengio, 2010]. Typically, the Xavier initialization samples weights from a Gaussian distribution with zero mean and variance  <span class="math notranslate nohighlight">\(\sigma^2=\frac{2}{(n_{in}+n_{out})}\)</span>,</p>
<div class="amsmath math notranslate nohighlight" id="equation-5b945ccc-a5b9-4b6b-9177-5c8747f55646">
<span class="eqno">(36)<a class="headerlink" href="#equation-5b945ccc-a5b9-4b6b-9177-5c8747f55646" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
w_{ij} \sim \mathcal{N} \left (\mu=0, \sigma=\sqrt{\frac{2}{(n_{in}+n_{out})}} \right)
\end{equation}\]</div>
<p>We can also adapt Xavierâ€™s intuition to choose the variance when sampling weights from a uniform distribution. Note that the uniform distribution <span class="math notranslate nohighlight">\(U(âˆ’a,a)\)</span> has variance <span class="math notranslate nohighlight">\(\frac{a^2}{3}\)</span>. Plugging this into our condition on <span class="math notranslate nohighlight">\(\sigma^2\)</span> yields the suggestion to initialize according to</p>
<div class="amsmath math notranslate nohighlight" id="equation-7164442e-47a6-42c1-866e-947df4f5d984">
<span class="eqno">(37)<a class="headerlink" href="#equation-7164442e-47a6-42c1-866e-947df4f5d984" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
w_{ij} \sim  \mathcal{U} \left(-\sqrt{\frac{6}{n_\mathrm{in} + n_\mathrm{out}}}, \sqrt{\frac{6}{n_\mathrm{in} + n_\mathrm{out}}}\right)
\end{equation}\]</div>
<p>This explanation is mainly taken from <a class="reference external" href="https://d2l.ai/chapter_multilayer-perceptrons/numerical-stability-and-init.html">here</a>.</p>
<p>If you want to see more about initializations and their differences see <a class="reference external" href="https://www.deeplearning.ai/ai-notes/initialization/">here</a>.</p>
</div>
<div class="section" id="section-3-2-initialization-with-transfer-function">
<h2>Section 3.2: Initialization with transfer function<a class="headerlink" href="#section-3-2-initialization-with-transfer-function" title="Permalink to this headline">Â¶</a></h2>
<p>Letâ€™s derive the optimal gain for LeakyReLU following similar steps.</p>
<p>LeakyReLU is described mathematically:</p>
<div class="amsmath math notranslate nohighlight" id="equation-6cc94a7f-2ff0-4dad-b9eb-2736d03fd956">
<span class="eqno">(38)<a class="headerlink" href="#equation-6cc94a7f-2ff0-4dad-b9eb-2736d03fd956" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
f(x)=\left\{
  \begin{array}{ll}
    \alpha \cdot x &amp; \text { for } x&lt;0 \\
    x &amp; \text { for } x \geq 0
  \end{array}\right.
\end{equation}\]</div>
<p>where <span class="math notranslate nohighlight">\(\alpha\)</span> controls the angle of the negative slope.</p>
<p>Considering a single layer with this activation function gives,</p>
<div class="amsmath math notranslate nohighlight" id="equation-8140521f-41f2-4f6e-9367-90953ecad94f">
<span class="eqno">(39)<a class="headerlink" href="#equation-8140521f-41f2-4f6e-9367-90953ecad94f" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
o_{i} &amp;= \sum_{j=1}^{n_\mathrm{in}} w_{ij} x_j\\
z_{i} &amp;= f\left( o_{i} \right)
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_i\)</span> denotes the activation of node <span class="math notranslate nohighlight">\(i\)</span>.</p>
<p>The expectation of the output is still zero, i.e., <span class="math notranslate nohighlight">\(\mathbb{E}[f(o_i)=0]\)</span>, but the variance changes, and assuming that the probability <span class="math notranslate nohighlight">\(P(x &lt; 0) = 0.5\)</span>, we have that:</p>
<div class="amsmath math notranslate nohighlight" id="equation-3797064f-b3b8-4dab-bf00-b1e55c4ca479">
<span class="eqno">(40)<a class="headerlink" href="#equation-3797064f-b3b8-4dab-bf00-b1e55c4ca479" title="Permalink to this equation">Â¶</a></span>\[\begin{align}
\mathrm{Var}[f(o_i)] &amp;= \mathbb{E}[f(o_i)^2] - \left( \mathbb{E}[f(o_i)] \right)^{2} \\ \\
&amp;= \frac{\mathrm{Var}[o_i] + \alpha^2 \mathrm{Var}[o_i]}{2} \\ \\
&amp;= \frac{1+\alpha^2}{2}n_\mathrm{in} \sigma^2 \gamma^2
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\gamma\)</span> is the variance of the distribution of the inputs <span class="math notranslate nohighlight">\(x_j\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> is the variance of the distribution of weights <span class="math notranslate nohighlight">\(w_{ij}\)</span>, as before.</p>
<p>Therefore, following the rest of derivation as before,</p>
<br/>
<div class="amsmath math notranslate nohighlight" id="equation-47e2cb4a-f6ca-43a9-aab4-a41a8d41d1ea">
<span class="eqno">(41)<a class="headerlink" href="#equation-47e2cb4a-f6ca-43a9-aab4-a41a8d41d1ea" title="Permalink to this equation">Â¶</a></span>\[\begin{equation}
\sigma = gain\sqrt{\frac{2}{n_\mathrm{in} + n_\mathrm{out}}}, \, \text{where} \,\, gain = \sqrt{\frac{2}{1+\alpha^2}}
\end{equation}\]</div>
<p>As we can see from the derived formula of <span class="math notranslate nohighlight">\(\sigma\)</span>, the transfer function we choose is related with the variance of the distribution of the weights. As the negative slope of the LeakyReLU <span class="math notranslate nohighlight">\(\alpha\)</span> becomes larger, the <span class="math notranslate nohighlight">\(gain\)</span> becomes smaller and thus, the distribution of the weights is narrower. On the other hand, as <span class="math notranslate nohighlight">\(\alpha\)</span> becomes smaller and smaller, the distribution of the weights is wider. Recall that, we initialize our weights, for example, by sampling from a normal distribution with zero mean and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>,</p>
</div>
<div class="section" id="best-gain-for-xavier-initialization-with-leaky-relu">
<h2>Best gain for Xavier Initialization with Leaky ReLU<a class="headerlink" href="#best-gain-for-xavier-initialization-with-leaky-relu" title="Permalink to this headline">Â¶</a></h2>
<p>Youâ€™re probably running out of time, so let me explain whatâ€™s happening here. We derived a theoretical gain for initialization. But the question is whether it holds in practice? Here we have a setup to confirm our finding. We will try a range of gains and see the empirical optimum and whether it matches our theoretical value!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">set_seed</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1"># number of trials</span>
<span class="n">gains</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="n">N</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">test_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">train_accs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">gain</span> <span class="ow">in</span> <span class="n">gains</span><span class="p">:</span>

  <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">xavier_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">gain</span><span class="p">)</span>
        <span class="c1"># torch.nn.init.xavier_uniform_(m.weight, gain)</span>

  <span class="n">negative_slope</span> <span class="o">=</span> <span class="mf">0.1</span>
  <span class="n">actv</span> <span class="o">=</span> <span class="s1">'LeakyReLU(</span><span class="si">%f</span><span class="s1">)'</span><span class="o">%</span><span class="k">negative_slope</span>
  <span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">(</span><span class="n">actv</span><span class="p">,</span> <span class="mi">3</span><span class="o">*</span><span class="mi">32</span><span class="o">*</span><span class="mi">32</span><span class="p">,</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">32</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
  <span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
  <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">)</span>
  <span class="n">train_acc</span><span class="p">,</span> <span class="n">test_acc</span> <span class="o">=</span> <span class="n">train_test_classification</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span>
                                                  <span class="n">img_train_loader</span><span class="p">,</span>
                                                  <span class="n">img_test_loader</span><span class="p">,</span>
                                                  <span class="n">DEVICE</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                                                  <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="n">test_accs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">test_acc</span><span class="p">]</span>
  <span class="n">train_accs</span> <span class="o">+=</span> <span class="p">[</span><span class="n">train_acc</span><span class="p">]</span>

<span class="n">best_gain</span> <span class="o">=</span> <span class="n">gains</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">train_accs</span><span class="p">)]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gains</span><span class="p">,</span> <span class="n">test_accs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Test acc'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">gains</span><span class="p">,</span> <span class="n">train_accs</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Train acc'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">best_gain</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_accs</span><span class="p">),</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'best gain = </span><span class="si">{</span><span class="n">best_gain</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s1">'r'</span><span class="p">)</span>
<span class="n">theoretical_gain</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mf">2.0</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">negative_slope</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">theoretical_gain</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">train_accs</span><span class="p">),</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s1">'theoretical gain = </span><span class="si">{</span><span class="n">theoretical_gain</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">'</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s1">'g'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="section-4-ethical-aspects">
<h1>Section 4: Ethical aspects<a class="headerlink" href="#section-4-ethical-aspects" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="video-4-ethics-hype-in-ai">
<h2>Video 4: Ethics: Hype in AI<a class="headerlink" href="#video-4-ethics-hype-in-ai" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<hr class="docutils"/>
<div class="section" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">Â¶</a></h1>
<p>In the second tutorial of this day, we have dived deeper into MLPs and seen more of their mathematical and practical aspects. More specifically, we have learned about different architectures, i.e., deep, wide, and how they are dependent on the transfer function used. Also, we have learned about the importance of initialization, and we mathematically analyzed two methods for smart initialization.</p>
<div class="section" id="video-5-outro">
<h2>Video 5: Outro<a class="headerlink" href="#video-5-outro" title="Permalink to this headline">Â¶</a></h2>
<div class="cell tag_remove-input docutils container">
</div>
</div>
</div>
<script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./tutorials/W1D3_MultiLayerPerceptrons/student"
        },
        predefinedOutput: true
    }
    </script>
<script>kernelName = 'python3'</script>
</div>
<div class="prev-next-bottom">
<a class="left-prev" href="W1D3_Tutorial1.html" id="prev-link" title="previous page">Tutorial 1: Biological vs. Artificial neurons</a>
<a class="right-next" href="../../W1D4_Optimization/chapter_title.html" id="next-link" title="next page">Optimization</a>
</div>
</div>
</div>
<footer class="footer mt-5 mt-md-0">
<div class="container">
<p>
        
          By Neuromatch<br>
        
            Â© Copyright 2021.<br/>
</br></p>
</div>
</footer>
</main>
</div>
</div>
<script src="../../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>
</body>
</html>